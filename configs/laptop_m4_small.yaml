device: mps                    # Apple Silicon GPU; fallback to cpu if unavailable
precision: fp16                # or bf16 if supported; keeps VRAM lower
seed: 42

data:
  train_manifest: data/manifests/train.jsonl
  val_manifest: data/manifests/val.jsonl
  sample_rate: 44100
  target_lufs: -14
  manifest_audio_key: audio
  manifest_label_key: label
  n_mels: 64                   # Reduced from 128 (fixes torchaudio warning)
  hop_length: 512
  segment_seconds: 8           # shorten if memory spikes
  num_workers: 2               # keep low to avoid host thrash
  cache_mels: true             # prefer precomputed mels

dataloader:
  batch_size: 4                # adjust to 2 if OOM; raise if stable
  shuffle: true
  pin_memory: false            # MPS: leave false
  drop_last: true

model:
  backbone: htsat-small        # small audio transformer/CNN
  embedding_dim: 256
  num_layers: 6
  num_heads: 4
  ff_mult: 2.0
  dropout: 0.1
  tasks:
    - name: genre
      head: linear
      classes: 20
      loss_weight: 3.0              # Boost genre (was under-weighted)
      auto_class_weights: true      # Auto-compute from label distribution
    - name: emotion
      head: linear
      classes: 8
      loss_weight: 0.5              # Reduce emotion (already near-perfect)

optim:
  name: adamw
  lr: 3e-4
  weight_decay: 0.01
  betas: [0.9, 0.98]
  grad_clip: 1.0

scheduler:
  name: cosine
  warmup_steps: 500
  max_steps: 40000             # Doubled for longer training

training:
  epochs: 20                   # Doubled epochs
  log_every: 50
  eval_every: 500
  ckpt_every: 1000
  grad_accum_steps: 2          # effectively doubles batch without memory spike
  ema: false                   # enable later if stable

augment:
  enabled: true
  time_stretch: [0.85, 1.15]   # Wider range for genre diversity
  pitch_shift_semitones: [-3, 3]
  eq_tilt_db: [-4, 4]          # Stronger EQ for genre (timbral variation)
  noise_snr_db: [20, 40]
  reverb_ir: null              # skip heavy IR conv on laptop; add later
  # Genre-specific augmentations
  mixup_alpha: 0.3             # Enable mixup for regularization
  spec_augment:
    freq_mask_param: 8         # SpecAugment frequency masking
    time_mask_param: 40        # SpecAugment time masking
    n_freq_masks: 2
    n_time_masks: 2

